# Core ML/NLP Libraries
torch>=2.1.0
transformers>=4.36.0
sentence-transformers>=2.2.0
langchain>=0.1.0
openai>=1.6.0
anthropic>=0.7.0

# Vector Databases & Retrieval
faiss-cpu>=1.7.4
pinecone-client>=2.2.4
chromadb>=0.4.0
qdrant-client>=1.7.0

# Data Processing
numpy>=1.24.0
pandas>=2.0.0
scipy>=1.10.0
scikit-learn>=1.3.0
datasets>=2.14.0
pyarrow>=14.0.0

# Visualization & Monitoring
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.17.0
wandb>=0.15.0
tensorboard>=2.14.0

# Model Optimization
onnx>=1.15.0
onnxruntime-gpu>=1.16.0
triton>=2.1.0
bitsandbytes>=0.41.0
accelerate>=0.24.0
peft>=0.7.0  # For QLoRA

# Evaluation & Metrics
rouge-score>=0.1.2
bert-score>=0.3.13
nltk>=3.8.0
sacrebleu>=2.3.0

# Development Tools
pytest>=7.4.0
pytest-cov>=4.1.0
black>=23.0.0
flake8>=6.1.0
mypy>=1.5.0
pre-commit>=3.5.0

# Documentation
mkdocs>=1.5.0
mkdocs-material>=9.4.0
mkdocstrings>=0.23.0
mkdocstrings-python>=1.7.0

# API & Web
fastapi>=0.104.0
uvicorn>=0.24.0
pydantic>=2.5.0
httpx>=0.25.0

# Utilities
tqdm>=4.66.0
pyyaml>=6.0.1
click>=8.1.0
python-dotenv>=1.0.0
loguru>=0.7.0
hydra-core>=1.3.0

# Jupyter & Notebooks
jupyter>=1.0.0
ipywidgets>=8.1.0
notebook>=7.0.0

# GPU Monitoring
nvidia-ml-py>=12.535.0
gpustat>=1.1.1

# Optional: Model-specific packages
# For Llama models
# llama-cpp-python>=0.2.0

# For Mixtral
# mixtral>=0.1.0

# Database
sqlalchemy>=2.0.0
alembic>=1.12.0

# Async support
aiohttp>=3.9.0
asyncio>=3.4.3
